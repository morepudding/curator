from llama_cpp import Llama
import time

print("ğŸ”§ Chargement modÃ¨le Mistral 7B...")

llm = Llama(
    model_path="./models/mistral-7b-instruct-q4.gguf",
    n_ctx=2048,
    n_gpu_layers=35
)

print("âœ… ModÃ¨le chargÃ© !\n")

prompt = """<s>[INST] Generate a D&D mission description.

Type: Infiltration
Location: Dark Cave (north of village)
Objective: Retrieve stolen artifact
Difficulty: Medium (7/10)

Generate:
1. Mission description (200-250 words) - urgent, tense tone
2. Success text (100 words) - victorious tone
3. Failure text (100 words) - consequences tone

Format clearly with headers.
[/INST]"""

print("ğŸ“ GÃ©nÃ©ration mission...\n")
start = time.time()

output = llm(
    prompt,
    max_tokens=600,
    temperature=0.75,
    top_p=0.9,
    stop=["</s>", "[INST]"]
)

elapsed = time.time() - start
response = output['choices'][0]['text'].strip()

print("=" * 60)
print("ğŸ—ºï¸  MISSION GÃ‰NÃ‰RÃ‰E :")
print("=" * 60)
print(response)
print("=" * 60)
print(f"\nâ±ï¸  Temps gÃ©nÃ©ration : {elapsed:.2f}s")
print(f"ğŸ“Š Nombre de mots : {len(response.split())}")
print(f"ğŸ”¢ Tokens gÃ©nÃ©rÃ©s : {output['usage']['completion_tokens']}")
